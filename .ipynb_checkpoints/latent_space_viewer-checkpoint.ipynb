{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa4bc92-91da-4a9a-b090-02fd403054bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import make_dataset\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e2a339-61d2-4430-9a4e-5bb2503fe278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#gui_env = [i for i in matplotlib.rcsetup.interactive_bk]\n",
    "#non_gui_backends = matplotlib.rcsetup.non_interactive_bk\n",
    "#print (\"Non Gui backends are:\", non_gui_backends)\n",
    "#print (\"Gui backends I will test for\", gui_env)\n",
    "#for gui in gui_env:\n",
    "#    print (\"testing\", gui)\n",
    "#    try:\n",
    "#        matplotlib.use(gui,warn=False, force=True)\n",
    "#        from matplotlib import pyplot as plt\n",
    "#        print (\"    \",gui, \"Is Available\")\n",
    "#        plt.plot([1.5,2.0,2.5])\n",
    "#        fig = plt.gcf()\n",
    "#        fig.suptitle(gui)\n",
    "#        plt.show()\n",
    "#        print (\"Using ..... \",matplotlib.get_backend())\n",
    "#    except:\n",
    "#        print (\"    \",gui, \"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2ddd3e-8613-417e-b13a-ac6b4acc544a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a340b1f0-c3fd-4433-b138-c9cbd6d5d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make model\n",
    "class Sampling(layers.Layer):\n",
    "        \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            batch = tf.shape(z_mean)[0]\n",
    "            dim = tf.shape(z_mean)[1]\n",
    "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(32, 300, 1))\n",
    "x = layers.Conv2D(64, (2,3), activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(128, (2,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16*latent_dim, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, \n",
    "                         kernel_initializer='zeros',\n",
    "                         name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "#encoder.summary()\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(8 * 75 * 128, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((8, 75, 128))(x)\n",
    "x = layers.Conv2DTranspose(64, (2,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(128, (2,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation='relu', padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "#decoder.summary()\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b10e7bf-efc4-40db-ab77-1b4d571e101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load latest weights\n",
    "list_of_files = glob.glob(os.path.join(os.getcwd(),'checkpoint_latdim{}'.format(latent_dim),'*'))\n",
    "weights_fname = max(list_of_files, key=os.path.getmtime)\n",
    "vae.built = True;\n",
    "vae.load_weights(weights_fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d51e59-f378-433b-a3b0-ac8b8501671d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim_sliders = list()\n",
    "\n",
    "for i in range(latent_dim):\n",
    "    dim_sliders.append(widgets.FloatSlider(\n",
    "        value = 0,\n",
    "        min = -20.0,\n",
    "        max = 20.0,\n",
    "        step = 0.1,\n",
    "        continuous_update = False,\n",
    "        description = 'Dim {}'.format(i+1),\n",
    "        orientation = 'horizontal'))\n",
    "\n",
    "slider_box = widgets.HBox(dim_sliders)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940eba34-1156-4c45-997d-04d750f4f278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def on_value_change(change):\n",
    "    z = list()\n",
    "    for i in range(latent_dim):\n",
    "        z.append(dim_sliders[i].value)\n",
    "    z = np.array(z)\n",
    "    print(z)\n",
    "    update_image(z)\n",
    "        \n",
    "for i in range(latent_dim):\n",
    "    dim_sliders[i].observe(on_value_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e861cc0-bfdc-42c8-986b-2a07bb9f6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image(z):\n",
    "    input_tensor = tf.constant(z, shape=[1,latent_dim])\n",
    "    new_data = vae.decoder.predict(input_tensor)\n",
    "    (_,r,c,_) = new_data.shape\n",
    "    new_data = new_data.reshape([r,c])\n",
    "\n",
    "    #image = PIL.Image.fromarray(new_data,'L')\n",
    "    f = plt.figure(figsize = [18,4])\n",
    "    cur_axis = f.add_axes([0,0,1,1])\n",
    "    cur_axis.set_axis_off()\n",
    "    cur_axis.imshow(new_data)\n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3928cc78-af80-4a85-a7c8-ce5cac2279fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4a38f73860469fbbfb34c0813aa8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, continuous_update=False, description='Dim 1', max=20.0, min=-20.0), Floaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-6dfa9f95f3aa>:13: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  f.show()\n"
     ]
    }
   ],
   "source": [
    "#set initial state\n",
    "display(slider_box)\n",
    "z = list()\n",
    "for i in range(latent_dim):\n",
    "    z.append(dim_sliders[i].value)\n",
    "z = np.array(z)\n",
    "update_image(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1abec9e9-32c0-4cfe-b4b0-02adeb10a5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1761 files belonging to 1 classes.\n",
      "Found 126 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = 'RGCtypes_1887'\n",
    "[train_set, test_set] = make_dataset.load_dataset_no_labels(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebaaff2-7f91-40dd-9431-ecec50b21119",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean,_,_ = vae.encoder.predict(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6e413-3f27-4829-a44a-5c33c9dd0288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(z_mean[:, 0], z_mean[:, 2])\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b931eb2-af1c-442f-8c78-278f43196a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13e319-530a-4ebc-b0fe-84d5838f50f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
